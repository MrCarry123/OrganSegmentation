{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrCarry123/OrganSegmentation/blob/main/CNNTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGxoODlQPZcb",
        "outputId": "e90ac5a3-9c4a-4b48-ec1b-8343cb7f6354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/MyDrive/Organsegmentation2/') #change this path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip3 install tensorflow==2.9.3\n",
        " !pip3 install keras==2.9.0\n",
        " !pip3 install -U segmentation-models"
      ],
      "metadata": {
        "id": "mTUqQ8BD0WJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1T8ftjcWcxd",
        "outputId": "70c40e3f-5ba3-473d-984a-40f9b7b48596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: SM_FRAMEWORK=tf.keras\n",
            "Segmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "\n",
        "%env SM_FRAMEWORK=tf.keras\n",
        "import segmentation_models as sm\n",
        "tf.keras.backend.set_image_data_format('channels_last')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0IwHtH5PZcd"
      },
      "outputs": [],
      "source": [
        "import segmentation_models as sm\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import nibabel as nib\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Conv2DTranspose, concatenate, BatchNormalization, Activation, MaxPool2D\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "# from nilearn.image import resample_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os\n",
        "import time\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import binary_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MZGd1xTuPN9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzAriq4qPZce"
      },
      "outputs": [],
      "source": [
        "# Uncomment to select the model\n",
        "#from resnet50_unet import build_resnet50_unet\n",
        "#from vgg16_unet import build_vgg16_unet\n",
        "from vgg19_unet import build_vgg19_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTmPyzf-PZce"
      },
      "outputs": [],
      "source": [
        "# names = os.listdir('/hdd_storage/data/sumitk/ct_org/train_labels/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eU6tzdDJPZcf"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BufbadmVPZcf"
      },
      "outputs": [],
      "source": [
        "def np_load_and_preprocess(file_path):\n",
        "    original_image = cv2.imread(str(file_path.decode()))\n",
        "    # print('original:', original_image.shape)\n",
        "    # Resize the image to (32, 32) and convert it to (32, 32, 3)\n",
        "    resized_image = cv2.resize(original_image, (32, 32)).astype(np.float32)\n",
        "    original_label = cv2.imread(str(file_path.decode()).replace('images', 'labels').replace('volume', 'labels'))\n",
        "\n",
        "    # Resize the image to (32, 32) and convert it to (32, 32, 3)\n",
        "    resized_label = cv2.resize(original_label, (32, 32)).astype(np.float32)\n",
        "    resized_label[resized_label != 0] = 1\n",
        "    # print('check: ', resized_image.shape, resized_label.shape)\n",
        "    return resized_image, resized_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF9phJKjPZcg"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess a single file\n",
        "def load_and_preprocess_file(file_path):\n",
        "    # Use tf.numpy_function to wrap the function and use NumPy functions inside TensorFlow\n",
        "    images, labels = tf.numpy_function(np_load_and_preprocess, [file_path], [tf.float32, tf.float32])\n",
        "    # images = preprocess_input(images)\n",
        "    # images = images[:, :,63]\n",
        "    # labels = labels[:, :,63]\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fmL8ab9PZcg"
      },
      "outputs": [],
      "source": [
        "# change path\n",
        "# remove [:100] for training with full dataset\n",
        "volume_files = glob('/content/drive/MyDrive/Organsegmentation2/train_images/*.png')\n",
        "# random.shuffle(volume_files)\n",
        "#volume_files = volume_files[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(volume_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzj3fuq_Rqy2",
        "outputId": "876cb002-f0ba-43ad-a6e9-390cdfe006db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53760"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZbIoyWPPZcg"
      },
      "outputs": [],
      "source": [
        "train_files, val_files = train_test_split(volume_files, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nqdTOpNPZcg"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_files).shuffle(buffer_size=len(train_files))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(val_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD4kux2-PZcg"
      },
      "outputs": [],
      "source": [
        "# Map the load_and_preprocess_file function to the dataset\n",
        "train_dataset = train_dataset.map(load_and_preprocess_file, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "# val_dataset = tf.data.Dataset.from_tensor_slices(val_files)\n",
        "val_dataset = val_dataset.map(load_and_preprocess_file, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "# In[14]:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOKotJOVPZcg"
      },
      "outputs": [],
      "source": [
        "# Shuffle, batch, cache, and prefetch the dataset\n",
        "batch_size = 32\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(train_files))\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "#train_dataset = train_dataset.cache()\n",
        "#train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5O1Vkw8fPZch"
      },
      "outputs": [],
      "source": [
        "# for step, (x,y) in enumerate(train_dataset):\n",
        "#     print(x)\n",
        "#     print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "671tAP8MPZch"
      },
      "outputs": [],
      "source": [
        "val_dataset = val_dataset.shuffle(buffer_size=len(val_files))\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "#val_dataset = val_dataset.cache()\n",
        "#val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEcrT97QPZch"
      },
      "outputs": [],
      "source": [
        "# Uncomment to use Custom U-Net model\n",
        "\n",
        "# def unet(label_num=4, pretrained_weights=None):\n",
        "\n",
        "#     inputs = Input((32, 32, 4))\n",
        "\n",
        "#     '''downsample'''\n",
        "#     conv1 = Conv2D(8, 3, padding='same', kernel_initializer='he_normal')(inputs)\n",
        "#     batc1 = BatchNormalization(axis=-1)(conv1)\n",
        "#     acti1 = Activation('relu')(batc1)\n",
        "#     conv2 = Conv2D(16, 3 , padding='same', kernel_initializer='he_normal')(acti1)\n",
        "#     batc2 = BatchNormalization(axis=-1)(conv2)\n",
        "#     acti2 = Activation('relu')(batc2)\n",
        "#     maxp1 = MaxPooling2D(2)(acti2)\n",
        "\n",
        "\n",
        "#     conv3 = Conv2D(16, 3, padding='same', kernel_initializer='he_normal')(maxp1)\n",
        "#     batc3 = BatchNormalization(axis=-1)(conv3)\n",
        "#     acti3 = Activation('relu')(batc3)\n",
        "#     conv4 = Conv2D(32, 3, padding='same', kernel_initializer='he_normal')(acti3)\n",
        "#     batc4 = BatchNormalization(axis=-1)(conv4)\n",
        "#     acti4 = Activation('relu')(batc4)\n",
        "#     maxp2 = MaxPooling2D(2)(acti4)\n",
        "\n",
        "\n",
        "#     conv5 = Conv2D(32, 3, padding='same', kernel_initializer='he_normal')(maxp2)\n",
        "#     batc5 = BatchNormalization(axis=-1)(conv5)\n",
        "#     acti5 = Activation('relu')(batc5)\n",
        "#     conv6 = Conv2D(128, 3, padding='same', kernel_initializer='he_normal')(acti5)\n",
        "#     batc6 = BatchNormalization(axis=-1)(conv6)\n",
        "#     acti6 = Activation('relu')(batc6)\n",
        "#     maxp3 = MaxPooling2D(2)(acti6)\n",
        "\n",
        "#     conv7 = Conv2D(64, 3, padding='same', kernel_initializer='he_normal')(maxp3)\n",
        "#     batc7 = BatchNormalization(axis=-1)(conv7)\n",
        "#     acti7 = Activation('relu')(batc7)\n",
        "#     conv8 = Conv2D(128, 3, padding='same', kernel_initializer='he_normal')(acti7)\n",
        "#     batc8 = BatchNormalization(axis=-1)(conv8)\n",
        "#     acti8 = Activation('relu')(batc8)\n",
        "\n",
        "\n",
        "#     '''upsample'''\n",
        "#     upsa1 = UpSampling2D(2)(acti8)\n",
        "#     # print('upsam1 shape: ', upsam1.shape)\n",
        "#     # Calculate the cropping amount for conv6\n",
        "#     # crop_amount = 1  # Adjust this calculation as needed based on your specific requirements\n",
        "\n",
        "#     # # # Crop conv6 to match the dimensions of upsa1\n",
        "#     # # cropped_conv6 = Cropping3D(cropping=((0, 0), (0, 0), (crop_amount, crop_amount)))(conv6)\n",
        "#     # sliced_conv6 = conv6[:, crop_amount:-crop_amount, crop_amount:-crop_amount, crop_amount:-crop_amount, :]\n",
        "\n",
        "#     # print(tf.shape(conv6[:, :, :, :16, :]))\n",
        "#     # print(tf.shape(upsa1))\n",
        "#     merg1 = Concatenate(axis=-1)([conv6, upsa1])\n",
        "\n",
        "#     # merg1 = Concatenate(axis=-1)([conv6[:, :, :, :16, :], upsa1])\n",
        "#     conv9 = Conv2D(64, 3, padding='same', kernel_initializer='he_normal')(merg1)\n",
        "#     batc9 = BatchNormalization(axis=-1)(conv9)\n",
        "#     acti9 = Activation('relu')(batc9)\n",
        "#     conv10 = Conv2D(128, 3, padding='same', kernel_initializer='he_normal')(acti9)\n",
        "#     batc10 = BatchNormalization(axis=-1)(conv10)\n",
        "#     acti10 = Activation('relu')(batc10)\n",
        "\n",
        "#     upsa2 = UpSampling2D(2)(acti10)\n",
        "#     merg2 = Concatenate(axis=-1)([conv4, upsa2])\n",
        "#     conv11 = Conv2D(64, 3, padding='same', kernel_initializer='he_normal')(merg2)\n",
        "#     batc11 = BatchNormalization(axis=-1)(conv11)\n",
        "#     acti11 = Activation('relu')(batc11)\n",
        "#     conv12 = Conv2D(32, 3, padding='same', kernel_initializer='he_normal')(acti11)\n",
        "#     batc12 = BatchNormalization(axis=-1)(conv12)\n",
        "#     acti12 = Activation('relu')(batc12)\n",
        "#     # print(tf.shape(acti12))\n",
        "#     upsa3 = UpSampling2D(2)(acti12)\n",
        "#     # print(tf.shape(upsa3))\n",
        "#     # print(tf.shape(conv2))\n",
        "#     merg3 = Concatenate(axis=-1)([conv2, upsa3])\n",
        "#     conv13 = Conv2D(16, 3, padding='same', kernel_initializer='he_normal')(merg3)\n",
        "#     batc13 = BatchNormalization(axis=-1)(conv13)\n",
        "#     acti13 = Activation('relu')(batc13)\n",
        "#     conv14 = Conv2D(16, 3, padding='same', kernel_initializer='he_normal')(acti13)\n",
        "#     convol = Conv2D(label_num, 1, padding='same',activation='sigmoid')(conv14)\n",
        "\n",
        "\n",
        "#     model = Model(inputs=inputs, outputs=convol)\n",
        "#     #model.compile(optimizer=Adam(lr=1e-4), loss=dice_coef_loss, metrics=[dice_coef])\n",
        "#     # model.compile(optimizer=Adam(lr=1e-4), loss=dice_coef_loss, metrics=[dice_coef])\n",
        "#     #model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=[dice_coef])\n",
        "#     #model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#     # model.summary()\n",
        "\n",
        "#     if (pretrained_weights):\n",
        "#         model.load_weights(pretrained_weights)\n",
        "\n",
        "#     return model\n",
        "# model = unet(label_num=4, pretrained_weights=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4gmsIwzPZch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8088d535-3080-4e40-a451-1361c934c1e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to select the model\n",
        "#model = build_resnet50_unet((32, 32, 3))\n",
        "#model = build_vgg16_unet((32, 32, 3))\n",
        "model = build_vgg19_unet((32, 32, 3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "num_layers = len(model.layers)\n",
        "print(num_layers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFzs0Eqzl9yi",
        "outputId": "7b9ecf7a-2c09-4ac5-f806-3e47b13b15e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"VGG19_U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 32, 32, 64)   1792        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 32, 32, 64)   36928       ['block1_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 16, 16, 64)   0           ['block1_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, 16, 16, 128)  73856       ['block1_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, 16, 16, 128)  147584      ['block2_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 8, 8, 128)    0           ['block2_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, 8, 8, 256)    295168      ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, 8, 8, 256)    590080      ['block3_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, 8, 8, 256)    590080      ['block3_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv4 (Conv2D)          (None, 8, 8, 256)    590080      ['block3_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 4, 4, 256)    0           ['block3_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, 4, 4, 512)    1180160     ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, 4, 4, 512)    2359808     ['block4_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, 4, 4, 512)    2359808     ['block4_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv4 (Conv2D)          (None, 4, 4, 512)    2359808     ['block4_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 2, 2, 512)    0           ['block4_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, 2, 2, 512)    2359808     ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, 2, 2, 512)    2359808     ['block5_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, 2, 2, 512)    2359808     ['block5_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv4 (Conv2D)          (None, 2, 2, 512)    2359808     ['block5_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, 4, 4, 512)   1049088     ['block5_conv4[0][0]']           \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 4, 4, 1024)   0           ['conv2d_transpose_4[0][0]',     \n",
            "                                                                  'block4_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 4, 4, 512)    4719104     ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 4, 4, 512)   2048        ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 4, 4, 512)    0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 4, 4, 512)    2359808     ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 4, 4, 512)   2048        ['conv2d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 4, 4, 512)    0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2DTran  (None, 8, 8, 256)   524544      ['activation_9[0][0]']           \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 8, 8, 512)    0           ['conv2d_transpose_5[0][0]',     \n",
            "                                                                  'block3_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 8, 8, 256)    1179904     ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 8, 8, 256)    590080      ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2DTran  (None, 16, 16, 128)  131200     ['activation_11[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_transpose_6[0][0]',     \n",
            "                                                                  'block2_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 128)  295040      ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 128)  512        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 128)  147584      ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 128)  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2DTran  (None, 32, 32, 64)  32832       ['activation_13[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 32, 32, 128)  0           ['conv2d_transpose_7[0][0]',     \n",
            "                                                                  'block1_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 32, 32, 64)   73792       ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32, 32, 64)  256         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 32, 32, 64)   36928       ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 32, 32, 64)  256         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 32, 32, 3)    195         ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,172,163\n",
            "Trainable params: 31,168,323\n",
            "Non-trainable params: 3,840\n",
            "__________________________________________________________________________________________________\n",
            "54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwBU1H_pPZch"
      },
      "outputs": [],
      "source": [
        "opt = Adam(learning_rate=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htLkkPB-PZch"
      },
      "outputs": [],
      "source": [
        "def DiceBCELoss(targets, inputs):\n",
        "    smooth = 1e-6\n",
        "    inputs = tf.keras.backend.flatten(inputs)\n",
        "    targets = tf.keras.backend.flatten(targets)\n",
        "\n",
        "    BCE = tf.keras.losses.binary_crossentropy(targets, inputs)\n",
        "    intersection = tf.reduce_sum(targets * inputs)\n",
        "    dice_loss = 1.0 - (2.0 * intersection + smooth) / (tf.reduce_sum(targets) + tf.reduce_sum(inputs) + smooth)\n",
        "    Dice_BCE = BCE + dice_loss\n",
        "    return Dice_BCE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "from tqdm import tqdm\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Training loop\n",
        "    for step, (x, y) in tqdm(enumerate(train_dataset)):\n",
        "        # print(x.shape, y.shape)\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            pred = model(x, training=True)\n",
        "            loss_value = DiceBCELoss(y, pred)\n",
        "\n",
        "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "        opt.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Validation phase\n",
        "    val_loss = 0.0\n",
        "    val_steps = 0\n",
        "    for step, (val_x, val_y) in tqdm(enumerate(val_dataset)):\n",
        "        val_pred = model(val_x, training=False)\n",
        "        val_loss += DiceBCELoss(val_y, val_pred)\n",
        "        val_steps += 1\n",
        "    avg_val_loss = val_loss / val_steps\n",
        "\n",
        "    print(\"Epoch: %d, Training Loss: %.4f, Validation Loss: %.4f, Time: %.2f seconds\" % (epoch, loss_value.numpy(), avg_val_loss, time.time() - start_time))"
      ],
      "metadata": {
        "id": "z8cd7uvc0Rnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsgEnduDPZch",
        "outputId": "dc37b514-3a70-4055-ba8c-9877b39c1b71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "model.save('sm6.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlM6V67fPZch"
      },
      "outputs": [],
      "source": [
        "# !jupyter nbconvert --to  script 'sm.ipynb'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk6GnzLaPZch"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psa7mYDyPZch"
      },
      "outputs": [],
      "source": [
        "# # load your data\n",
        "\n",
        "\n",
        "# # preprocess input\n",
        "# x_train = preprocess_input(x_train)\n",
        "# x_val = preprocess_input(x_val)\n",
        "\n",
        "# # define model\n",
        "# model = sm.Unet('resnet34', classes=7, activation='softmax')\n",
        "# model.compile(\n",
        "#     'Adam',\n",
        "#     loss=sm.losses.bce_jaccard_loss,\n",
        "#     metrics=[sm.metrics.iou_score],\n",
        "# )\n",
        "\n",
        "# # fit model\n",
        "# # if you use data generator use model.fit_generator(...) instead of model.fit(...)\n",
        "# # more about `fit_generator` here: https://keras.io/models/sequential/#fit_generator\n",
        "# model.fit(\n",
        "#    x=x_train,\n",
        "#    y=y_train,\n",
        "#    batch_size=16,\n",
        "#    epochs=100,\n",
        "#    validation_data=(x_val, y_val),\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzYCNJkhPZci"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}